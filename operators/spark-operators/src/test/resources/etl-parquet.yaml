sources:
  - type: parquet                                 # SourceType: [csv, parquet, json, orc, jdbc, iceberg, hive]
    name: user                                    # name: unique source name
    output: user                                  # output: unique output
    options:
      paths: [ "src/test/resources/user.parquet" ]

transforms:
  - type: sparkSQL
    name: user-trans
    input:
      user: user_temp
    output: user_trans_output
    options:
      sql: select *, (FLOOR(RAND() * 100) - 10) as age from user_temp

sinks:
  - type: parquet                                      # sink type: [parquet, csv, json, jdbc, iceberg, hive]
    name: user-sink                                    # unique sink name
    input: user_trans_output                           # dataframe name
    writeMode: append                                  # write mode: [append, replace, create_or_replace, replace_by_time, overwrite_partitions]
    options:
      path: output/parquet